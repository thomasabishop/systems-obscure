---
title: "Initial thoughts on the practical benefits of ChatGPT"
slug: /chat-gpt-practical-benefits/
date: 2023-03-12
---

Like a lot of people who make software for a living I'm currently coming to
terms with ChatGPT. I have mixed feelings and conflicting thoughts.

My misgivings relate mostly to its social, political and cultural implications
rather than its practical utility. I will address these in a future post. Here,
I want to discuss the benefits from my point of view as a software engineer. I
will argue that for now at least, it is an asset to human programmers rather
then a threat.

The interaction pictured below marked the point at which I realised that there
was something of substance to the technology beyond the hype.

The Bash code I had written looked fine to me and I couldn't see what I was
doing wrong. Provided with the code and the expected output, ChatGPT identified
the problem immediately, saving me from potentially wasting a lot of time
scouring Stack Overflow for a solution.

A good linter or debugger can do the same, however. The difference with ChatGPT
is that I am also able to interrogate the AI about its response and seek
clarification as it relates to my broader objectives. I can do this confident in
the knowledge that it will retain a reference to the pertinent data in my
intitial query and be able to justify and elaborate on its responses.

It's this experience, or rather illusion, of _rational interchange_ that
suggests to me that ChatGPT and its successors will constitute a definitive
step-change in the way that people retrieve and process information. I think
this will prove especially true in practical fields that work with specialised,
more or less objective knowledge. (I am sceptical of its ability to generate
interesting perspectives on more humanistic topics, beyond summarising existing
literature.)

I know from my own case and from my time as a teacher that facts become
knowledge only when they are embedded within a web of related beliefs. Beliefs
that are constantly being revised and rejected based on their rational coherence
and their correspondance to truth. If you want a child to understand an abstract
concept and they do not simply grasp it in a flash of _a priori_ discernment,
the best thing you can do is present examples of the concept under different
aspects and in relation to things they _do_ know, whilst all the time
questioning them and encouraging them to verbalise their reasoning and question
you.

ChatGPT excels in this role of midwife to your ideas.[^nietzshe] It is like
having a patient and knowledgeable teacher at your side that turns frustrating
bugs and errors into opportunities for intellectual enrichment. I can query
ChatGPT on a shallow level about bugs and syntax but I can also ask for broader
advice on architectural questions and matters of style. _Which data structure
should I use for maximum efficiency?_, _How can I reduce repetition and achieve
greater abstraction?_, _How do I do this thing in Java that I can already do in
Python_? etc.

At least in its current form, I do not see this as a threat to my role as a
human programmer because real rational interchange is only possible if both
parties are conversant in the subject matter and are bound by the contraints of
truth and logical inference. Currently, ChatGPT falls short on both counts.

This is obviously true in light of the fact that the technology - compared with
what we would consider to be genuine general artificial intelligence - is a
glorified [Markovian regurgitator](https://en.wikipedia.org/wiki/Markov_chain)
of sampled data generated by humans. (Only those unaware of the challenges of
artificial intelligence and the broader project of cognitive science would
mistake this for intelligence or linguistic capacity, as Chomsky has
[predictably argued](https://web.archive.org/web/20230320095450/https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html).)
ChatGPT doesn't _know_ anything more than the man in the
[Chinese Room](https://plato.stanford.edu/entries/chinese-room/). Nor does it
have a concept of truth, as its well-documented "hallucinations" demonstrate.
For now, the human is the vital guarantor of the truth and relevance of the
output.

In order to be able to exploit the benefits of ChatGPT in the programming
context, I require a degree of knowledge sufficient to generate a good question
and follow-up with secondary queries that refine the initial response and check
it for truth. My (actual) knowledge is critical to the usefulness of the
exchange.

But these limitations are what make ChatGPT a _useful tool_ rather than a
competitor. It empowers and elevates the programmer rather than diminishing him.

This is the reason I was rather underwhelmed by GitHub Copilot. It provided no
mechanism to query or second-guess the code that it was generating, beyond
simply rejecting it. It made me feel diminished and effaced - a _user of
software_ rather than a _builder of software_. It was easy to imagine it
becoming an engine of mediocrity, where lazy programmers cobble together generic
but inelegant solutions that work without knowing why.

ChatGPT improves on this. It is aware of its fallibility and will accept when it
is told that it is wrong, reformulating its output in response. As long as it is
utilised with discernment and scepticism by a user that has sufficient knowledge
to hold it to account, ChatGPT is valuable tool for programming and personal
development, without yet quite being a surrogate for competent human engineers.

![](./img/chat-gpt-explanation-bug.png)

[^nietzshe]:
    "One person seeks a midwife for his thoughts; the other, someone he can
    assist. Here is the origin of a good conversation." Friedrich Nietzshe.
    _Beyond Good and Evil_. 1886.
